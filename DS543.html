<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<!-- saved from url=(0023)http://haipeng-luo.net/ -->
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/">

<link rel="stylesheet" href="./jemdoc.css" type="text/css">
<title>DS 543 Intro to RL</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tbody><tr valign="top">
<td id="layout-menu">
<div class="menu-category">Xuezhou Zhang</div>
<div class="menu-item"><a href="./index.html" class="current">Home</a></div>
<div class="menu-item"><a href="./CV.pdf" target="_blank" rel="noopener noreferrer">CV</a></div>
<div class="menu-category">Research</div>
<div class="menu-item"><a href="./projects.html">Projects</a></div>
<div class="menu-item"><a href="./pubs.html">Publications</a></div>
<div class="menu-item"><a href="./students.html">Students</a></div>
<div class="menu-category">Teaching</div>
<div class="menu-item"><a href="./DS543.html">DS543</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>DS 543 Introduction to Reinforcement Learning (Spring 2024)</h1>
</div>
This course aim to present a math-lite introduction to reinforcement learning.
We will cover <strong>(1) the basics of Markov Decision Processes (2) primary algorithmic paradigms including model-based, value-based and policy-based learning (3) modern challenges and open problems in RL</strong>.

<p>
    <br><strong>Instructors</strong>: <a href="https://zhangxz1123.github.io/">Xuezhou Zhang</a> <br>
    <br><strong>TF</strong>: <a href="https://myc000801.github.io/">Mingyu Chen</a> <br>
    <br><strong> Lecture time: </strong> Tuesday/Thursday 12:30pm - 1:45pm ET  <br>
    <br><strong>Instructor office hours: </strong> TBD<br>
    <br><strong>TF hours: </strong> TBD </a>.
<br>
</p>


<table width="80%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody><tr>
            <td width="100%" valign="middle">
              <p align="center">
                <heading>Schedule (The current materials are from Spring 2024)</heading>
              </p>
              
              <table>
		<tbody>
                  <tr height="50" bgcolor="#F8F8FF">
                    <td></td>
                    <td></td>
                    <td> <strong>Topics</strong></td>
                    <td>Reading</td>
                    <td>Slides/HW </td>
                  </tr>
		  
                  <tr height="50">
                    <td>Chapter 1</td>
                    <td></td>
                    <td> <strong>Fundamentals</strong>: Markov Decision Processes</td>
                    <td><a href="https://rltheorybook.github.io/rltheorybook_AJKS.pdf" target="_blank" rel="noopener noreferrer">AJKS</a>: 1.1, 1.2</td>
                    <td><a href="./DS_543/Lecture_1.pdf" target="_blank" rel="noopener noreferrer">Slides</a></td>
                  </tr>

                  <tr bgcolor="#F8F8FF" height="50">     
                    <td>Chapter 2</td>
                    <td></td>
                    <td><strong>Planning in MDPs</strong>: Policy and Value Itertions</td>
                    <td><a href="https://rltheorybook.github.io/rltheorybook_AJKS.pdf" target="_blank" rel="noopener noreferrer">AJKS</a>: 1.3</td>
                    <td><a href="./DS_543/Lecture_2.pdf" target="_blank" rel="noopener noreferrer">Slides</a>, <a href="./DS_543/DS543_HW1.pdf" target="_blank" rel="noopener noreferrer">HW1.pdf</a>, <a href="./DS_543/HW1.tex" target="_blank" rel="noopener noreferrer">HW1.tex</a></td>
                  </tr>


                <tr height="50">
                    <td>Chapter 3</td>
                    <td></td>
                <td><strong>Model-based RL</strong>: MPC, Dreamer, MuZero </td>
                    <td><a href="https://rltheorybook.github.io/rltheorybook_AJKS.pdf" target="_blank" rel="noopener noreferrer">AJKS</a>: 2.1, 2.3</td>
                    <td><a href="./DS_543/Lecture_3.pdf" target="_blank" rel="noopener noreferrer">Slides</a></td>
                  </tr>

                  <tr bgcolor="#F8F8FF" height="50">     
                    <td>Chapter 4</td>
                    <td></td>
                    <td><strong>Value-based RL</strong>: FQI, Q-learning</td>
                    <td><a href="https://rltheorybook.github.io/rltheorybook_AJKS.pdf" target="_blank" rel="noopener noreferrer">AJKS</a>: 4.1, 4.2</td>
                    <td><a href="./DS_543/Lecture_4.pdf" target="_blank" rel="noopener noreferrer">Slides</a>, <a href="./DS_543/DS543_project_doc.pdf" target="_blank" rel="noopener noreferrer">Project</a></td>
                  </tr>

                  <tr height="50">     
                    <td>Chapter 4</td>
                    <td></td>
                    <td><strong>Value-based RL</strong>: Bellman completeness, DQN</td>
                    <td><a href="https://rltheorybook.github.io/rltheorybook_AJKS.pdf" target="_blank" rel="noopener noreferrer">AJKS</a>: 4.1, 4.2</td>
                    <td><a href="./DS_543/Lecture_5.pdf" target="_blank" rel="noopener noreferrer">Slides</a></td>
                  </tr>

                  <tr height="50" bgcolor="#F8F8FF">
                    <td>Chapter 5</td>
                    <td></td>
                    <td><strong>Policy-based RL</strong>: Policy Gradient Theorem, Reinforce</td>
                    <td><a href="https://rltheorybook.github.io/rltheorybook_AJKS.pdf" target="_blank" rel="noopener noreferrer">AJKS</a>: 11-14</td>
                    <td><a href="./DS_543/Lecture_6.pdf" target="_blank" rel="noopener noreferrer">Slides</a></td>
                  </tr>

                  <tr height="50">
                    <td>Chapter 5</td>
                    <td></td>
                    <td><strong>Policy-based RL</strong>: Actor-Critic, Importance Sampling, DPG</td>
                    <td><a href="https://rltheorybook.github.io/rltheorybook_AJKS.pdf" target="_blank" rel="noopener noreferrer">AJKS</a>: 11-14</td>
                    <td><a href="./DS_543/Lecture_7.pdf" target="_blank" rel="noopener noreferrer">Slides</a>, <a href="./DS_543/HW2.pdf" target="_blank" rel="noopener noreferrer">HW2.pdf</a>, <a href="./DS_543/HW2.tex" target="_blank" rel="noopener noreferrer">HW2.tex</a></td>
                  </tr>

                  <tr height="50" bgcolor="#F8F8FF">
                    <td>Chapter 5</td>
                    <td></td>
                    <td><strong>Policy-based RL</strong>: NPG, TRPO, PPO</td>
                    <td><a href="https://rltheorybook.github.io/rltheorybook_AJKS.pdf" target="_blank" rel="noopener noreferrer">AJKS</a>: 11-14</td>
                    <td><a href="./DS_543/Lecture_8.pdf" target="_blank" rel="noopener noreferrer">Slides</a></td>
                  </tr>

                  <tr height="50">     
                    <td>Chapter 6</td>
                    <td></td>
                    <td><strong>Imitation Learning</strong>: Behavior Cloning</td>
                    <td><a href="https://rltheorybook.github.io/rltheorybook_AJKS.pdf" target="_blank" rel="noopener noreferrer">AJKS</a>: 15</td>
                    <td><a href="./DS_543/Lecture_9.pdf" target="_blank" rel="noopener noreferrer">Slides</a>, <a href="https://colab.research.google.com/drive/1ivh4hI_d78BDIkbg2OQ7i2VnNeYVNUU5?usp=sharing
" target="_blank" rel="noopener noreferrer">Pytorch Demo</a></td>
                  </tr>

                  <tr height="50" bgcolor="#F8F8FF">     
                    <td>Chapter 6</td>
                    <td></td>
                    <td><strong>Imitation Learning</strong>: Dagger</td>
                    <td><a href="https://rltheorybook.github.io/rltheorybook_AJKS.pdf" target="_blank" rel="noopener noreferrer">AJKS</a>: 15</td>
                    <td><a href="./DS_543/Lecture_10.pdf" target="_blank" rel="noopener noreferrer">Slides</a></td>
                  </tr>

                  <tr height="50">
                    <td>Chapter 7</td>
                    <td></td>
                    <td><strong>Exploration</strong>: Exploration in MAB</td>
                    <td><a href="https://rltheorybook.github.io/rltheorybook_AJKS.pdf" target="_blank" rel="noopener noreferrer">AJKS</a>: 6.1.1</td>
                    <td><a href="./DS_543/Lecture_12.pdf" target="_blank" rel="noopener noreferrer">Slides</a></td>
                  </tr>

                  <tr height="50" bgcolor="#F8F8FF">
                    <td>Chapter 7</td>
                    <td></td>
                    <td><strong>Exploration</strong>: Exploration in MAB</td>
                    <td><a href="https://rltheorybook.github.io/rltheorybook_AJKS.pdf" target="_blank" rel="noopener noreferrer">AJKS</a>: 6.1.1</td>
                    <td><a href="./DS_543/Lecture_13.pdf" target="_blank" rel="noopener noreferrer">Slides</a></td>
                  </tr>

                  <tr height="50">     
                    <td>Chapter 8</td>
                    <td></td>
                    <td><strong>Exploration</strong>: Exploration in MDPs</td>
                    <td><a href="https://rltheorybook.github.io/rltheorybook_AJKS.pdf" target="_blank" rel="noopener noreferrer">AJKS</a>: 7.2</td>
                    <td><a href="./DS_543/Lecture_14.pdf" target="_blank" rel="noopener noreferrer">Slides</a></td>
                  </tr>

                  <tr height="50" bgcolor="#F8F8FF">     
                    <td>Chapter 8</td>
                    <td></td>
                    <td><strong>Exploration</strong>: Exploration in Deep RL</td>
                    <td><a href="https://rltheorybook.github.io/rltheorybook_AJKS.pdf" target="_blank" rel="noopener noreferrer">AJKS</a>: 7.2</td>
                    <td><a href="./DS_543/Lecture_15.pdf" target="_blank" rel="noopener noreferrer">Slides</a>, <a href="./DS_543/HW3.ipynb" target="_blank" rel="noopener noreferrer">HW3</a></td>
                  </tr>

                  <tr height="50">     
                    <td>Chapter 9</td>
                    <td></td>
                    <td><strong>Offline RL</strong>: FQI and naive methods</td>
                    <td><a href="https://rltheorybook.github.io/rltheorybook_AJKS.pdf" target="_blank" rel="noopener noreferrer">AJKS</a>: 4.1</td>
                    <td><a href="./DS_543/Lecture_16.pdf" target="_blank" rel="noopener noreferrer">Slides</a></td>
                  </tr>

                  <tr height="50" bgcolor="#F8F8FF">     
                    <td>Chapter 9</td>
                    <td></td>
                    <td><strong>Offline RL</strong>: Learning without full data coverage</td>
                    <td><a href="https://rltheorybook.github.io/rltheorybook_AJKS.pdf" target="_blank" rel="noopener noreferrer">AJKS</a>: 4.1</td>
                    <td><a href="./DS_543/Lecture_17.pdf" target="_blank" rel="noopener noreferrer">Slides</a></td>
                  </tr>

                  <tr height="50">     
                    <td>Chapter 9</td>
                    <td></td>
                    <td><strong>Offline RL</strong>: LCB and Empirical Methods</td>
                    <td><a href="https://rltheorybook.github.io/rltheorybook_AJKS.pdf" target="_blank" rel="noopener noreferrer">AJKS</a>: 4.1</td>
                    <td><a href="./DS_543/Lecture_18.pdf" target="_blank" rel="noopener noreferrer">Slides</a></td>
                  </tr>

                  <tr height="50" bgcolor="#F8F8FF">
                    <td>Chapter 10</td>
                    <td></td>
                    <td><strong>Multi-agent RL</strong>: Game Theory Basics</td>
                    <td>TBD</td>
                    <td><a href="./DS_543/Lecture_19.pdf" target="_blank" rel="noopener noreferrer">Slides</a></td>
                  </tr>

                  <tr height="50">
                    <td>Chapter 10</td>
                    <td></td>
                    <td><strong>Multi-agent RL:</strong> Markov Games and Planning in MG</td>
                    <td>TBD</td>
                    <td><a href="./DS_543/Lecture_20.pdf" target="_blank" rel="noopener noreferrer">Slides</a></td>
                  </tr>

                  <tr height="50" bgcolor="#F8F8FF">
                    <td>Chapter 10</td>
                    <td></td>
                    <td><strong>Multi-agent RL</strong>: Online Learning in MGs</td>
                    <td>TBD</td>
                    <td><a href="./DS_543/Lecture_22.pdf" target="_blank" rel="noopener noreferrer">Slides</a></td>
                  </tr>

                  <tr height="50">
                    <td>Chapter 10.5</td>
                    <td></td>
                    <td><strong>Mechanism Design</strong>: Going beyond being a player in the game</td>
                    <td>TBD</td>
                    <td><a href="./DS_543/Lecture_23.pdf" target="_blank" rel="noopener noreferrer">Slides</a></td>
                  </tr>
          
               </tbody>
              </table>



            </td>
          </tr>
        </tbody></table>

<div id="footer">
</div>
</td>
</tr>
</tbody></table>


<iframe frameborder="0" scrolling="no" style="background-color: transparent; border: 0px; display: none;" src="./Haipeng Luo_files/saved_resource.html"></iframe><div id="GOOGLE_INPUT_CHEXT_FLAG" style="display: none;" input="" input_stat="{&quot;tlang&quot;:true,&quot;tsbc&quot;:true,&quot;pun&quot;:true,&quot;mk&quot;:true,&quot;ss&quot;:true}"></div></body></html>