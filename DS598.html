<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<!-- saved from url=(0023)http://haipeng-luo.net/ -->
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/">

<link rel="stylesheet" href="./jemdoc.css" type="text/css">
<title>DS 598 Intro to RL</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tbody><tr valign="top">
<td id="layout-menu">
<div class="menu-category">Xuezhou Zhang</div>
<div class="menu-item"><a href="./index.html" class="current">Home</a></div>
<div class="menu-item"><a href="./CV.pdf" target="_blank" rel="noopener noreferrer">CV</a></div>
<div class="menu-category">Research</div>
<div class="menu-item"><a href="./projects.html">Projects</a></div>
<div class="menu-item"><a href="./pubs.html">Publications</a></div>
<div class="menu-item"><a href="./students.html">Students</a></div>
<div class="menu-category">Teaching</div>
<div class="menu-item"><a href="./DS598.html">DS598</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>DS 598 Introduction to Reinforcement Learning</h1>
</div>
This course aim to present a math-lite introduction to reinforcement learning.
We will cover <strong>(1) the basics of Markov Decision Processes (2) primary algorithmic paradigms including model-based, value-based and policy-based learning (3) modern challenges and open problems in RL</strong>.

<p>
    <br><strong>Instructors</strong>: <a href="https://zhangxz1123.github.io/">Xuezhou Zhang</a> <br>
    <br><strong>TF</strong>: <a href="https://gaurav.koley.in/">Gaurav Koley</a> <br>
    <br><strong> Lecture time: </strong> Tuesday/Thursday 12:30pm - 1:45pm ET  <br>
    <br><strong>Instructor office hours: </strong> Tuesday and Thursday after class (1:45pm-3:00pm) <br>
                
    <br><strong>Contact:</strong> cds.intro.rl@gmail.com 
    </p><p> Please communicate to the instructors and TA only through this email with subject title as <strong>"[DS 598]..."</strong>. 
    Emails not sent to this list, with regards to the course,
    may not be responded to in a timely manner.
</p>


<table width="60%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody><tr>
            <td width="100%" valign="middle">
              <p align="center">
                <heading>Schedule (tentative)</heading>
              </p>
              
              <table>
		<tbody>
                  <tr height="50" bgcolor="#F8F8FF">
                    <td></td>
                    <td></td>
                    <td> <strong>Topics</strong></td>
                    <td>Reading</td>
                    <td>Slides/HW </td>
                  </tr>
		  
                  <tr height="50">
                    <td>Chapter 1</td>
                    <td></td>
                    <td> <strong>Fundamentals</strong>: Markov Decision Processes</td>
                    <td><a href="https://rltheorybook.github.io/rltheorybook_AJKS.pdf" target="_blank" rel="noopener noreferrer">AJKS</a>: 1.1, 1.2</td>
                    <td><a href="./Lecture_1.pdf" target="_blank" rel="noopener noreferrer">Slides</a></td>
                  </tr>

                  <tr height="50">     
                    <td>Chapter 2</td>
                    <td></td>
                    <td><strong>Planning in MDPs</strong>: Policy and Value Itertions</td>
                    <td><a href="https://rltheorybook.github.io/rltheorybook_AJKS.pdf" target="_blank" rel="noopener noreferrer">AJKS</a>: 1.3</td>
                    <td></td>
                  </tr>


                <tr bgcolor="#F8F8FF" height="50">
                    <td>Chapter 3</td>
                    <td></td>
                <td><strong>Model-based RL</strong>: Certainty Equivalence Learning </td>
                    <td><a href="https://rltheorybook.github.io/rltheorybook_AJKS.pdf" target="_blank" rel="noopener noreferrer">AJKS</a>: 2.1, 2.3</td>
                    <td></td>
                  </tr>

                  <tr height="50">     
                    <td>Chapter 4</td>
                    <td></td>
                    <td><strong>Value-based RL</strong>: Q-learning, DQN</td>
                    <td><a href="https://rltheorybook.github.io/rltheorybook_AJKS.pdf" target="_blank" rel="noopener noreferrer">AJKS</a>: 4.1, 4.2</td>
                    <td></td>
                  </tr>

                  <tr height="50" bgcolor="#F8F8FF">
                    <td>Chapter 5</td>
                    <td></td>
                    <td><strong>Policy-based RL</strong>: Reinforce, NPG, PPO</td>
                    <td><a href="https://rltheorybook.github.io/rltheorybook_AJKS.pdf" target="_blank" rel="noopener noreferrer">AJKS</a>: 15.2, 15.4</td>
                    <td></td>
                  </tr>

                  <tr height="50">     
                    <td>Chapter 6</td>
                    <td></td>
                    <td><strong>Imitation Learning</strong>: Behavior Cloning, Inverse RL, Dagger</td>
                    <td><a href="https://rltheorybook.github.io/rltheorybook_AJKS.pdf" target="_blank" rel="noopener noreferrer">AJKS</a>: 15.5</td>
                    <td></td>
                  </tr>

                  <tr height="50" bgcolor="#F8F8FF">
                    <td>Chapter 7</td>
                    <td></td>
                    <td><strong>Modern Challenges</strong>: Exploration in MAB</td>
                    <td><a href="https://rltheorybook.github.io/rltheorybook_AJKS.pdf" target="_blank" rel="noopener noreferrer">AJKS</a>: 6.1.1</td>
                    <td></td>
                  </tr>

                  <tr height="50">     
                    <td>Chapter 8</td>
                    <td></td>
                    <td><strong>Modern Challenges</strong>: Exploration in RL</td>
                    <td><a href="https://rltheorybook.github.io/rltheorybook_AJKS.pdf" target="_blank" rel="noopener noreferrer">AJKS</a>: 7.2</td>
                    <td></td>
                  </tr>

                  <tr height="50" bgcolor="#F8F8FF">
                    <td>Chapter 9</td>
                    <td></td>
                    <td><strong>Modern Challenges</strong>: Multi-agent RL</td>
                    <td></td>
                    <td></td>
                  </tr>

                  <tr height="50">     
                    <td>Chapter 10</td>
                    <td></td>
                    <td><strong>Modern Challenges</strong>: Partially Observable MDPs</td>
                    <td></td>
                    <td></td>
                  </tr>
          
               </tbody>
              </table>



            </td>
          </tr>
        </tbody></table>

<div id="footer">
</div>
</td>
</tr>
</tbody></table>


<iframe frameborder="0" scrolling="no" style="background-color: transparent; border: 0px; display: none;" src="./Haipeng Luo_files/saved_resource.html"></iframe><div id="GOOGLE_INPUT_CHEXT_FLAG" style="display: none;" input="" input_stat="{&quot;tlang&quot;:true,&quot;tsbc&quot;:true,&quot;pun&quot;:true,&quot;mk&quot;:true,&quot;ss&quot;:true}"></div></body></html>